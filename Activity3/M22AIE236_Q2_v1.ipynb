{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uea5aKGtMsUB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Roll NO : M22AIE236"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCDNpX2FMsrm"
      },
      "outputs": [],
      "source": [
        "#version : 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVp9KhJWMsx5",
        "outputId": "826cef72-5225-436a-fa44-ab858303260c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz to ./data/stl10_binary.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2640397119/2640397119 [04:01<00:00, 10935751.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/stl10_binary.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
            "100%|██████████| 171M/171M [00:01<00:00, 125MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with optimizer: Adam\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load STL10 dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "train_dataset = datasets.STL10(root='./data', split='train', download=True, transform=transform)\n",
        "test_dataset = datasets.STL10(root='./data', split='test', download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Step 2: Load pre-trained ResNet101 model\n",
        "resnet101 = models.resnet101(pretrained=True)\n",
        "num_ftrs = resnet101.fc.in_features\n",
        "resnet101.fc = nn.Linear(num_ftrs, 10)  # Replace final fully connected layer for 10 classes\n",
        "\n",
        "# Step 3: Define optimizers\n",
        "optimizers = {\n",
        "    'Adam': optim.Adam(resnet101.parameters(), lr=0.001),\n",
        "    'Adagrad': optim.Adagrad(resnet101.parameters(), lr=0.001),\n",
        "    'Adadelta': optim.Adadelta(resnet101.parameters(), lr=1.0)\n",
        "}\n",
        "\n",
        "# Step 4: Train the model with different optimizers\n",
        "num_epochs = 10\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "train_losses = {optimizer_name: [] for optimizer_name in optimizers}\n",
        "train_accuracies = {optimizer_name: [] for optimizer_name in optimizers}\n",
        "\n",
        "for optimizer_name, optimizer in optimizers.items():\n",
        "    print(f\"Training with optimizer: {optimizer_name}\")\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = resnet101(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        epoch_accuracy = 100.0 * correct / total\n",
        "\n",
        "        train_losses[optimizer_name].append(epoch_loss)\n",
        "        train_accuracies[optimizer_name].append(epoch_accuracy)\n",
        "\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n",
        "\n",
        "# Step 5: Plot training loss and accuracy curves\n",
        "plt.figure(figsize=(12, 6))\n",
        "for optimizer_name, losses in train_losses.items():\n",
        "    plt.plot(losses, label=f'{optimizer_name} Loss')\n",
        "\n",
        "plt.title('Training Loss Curves')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "for optimizer_name, accuracies in train_accuracies.items():\n",
        "    plt.plot(accuracies, label=f'{optimizer_name} Accuracy')\n",
        "\n",
        "plt.title('Training Accuracy Curves')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Step 6: Report final top-5 test accuracy\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        outputs = resnet101(images)\n",
        "        _, predicted = torch.topk(outputs, 5, dim=1)  # Get top-5 predictions\n",
        "        total += labels.size(0)\n",
        "        correct += sum([1 for i in range(labels.size(0)) if labels[i] in predicted[i]])\n",
        "\n",
        "    print(f\"Final Top-5 Test Accuracy: {100.0 * correct / total:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jd05Hh3YMtMl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
